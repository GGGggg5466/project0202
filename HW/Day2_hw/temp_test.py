from openai import OpenAI

client = OpenAI(
    base_url="https://ws-02.wade0426.me/v1",
    api_key="vllm-token",
)

MODEL_ID = "google/gemma-3-27b-it"  # âœ… ç”¨ä½  /v1/models çœ‹åˆ°çš„ id

prompt = "è«‹ç”¨100å­—å½¢å®¹ã€äººå·¥æ™ºæ…§ã€ã€‚"
temps = [0.1, 1.5]  # 0.1 å¾ˆç©©ã€1.5 å¾ˆç™¼æ•£

for t in temps:
    print(f"\nâ¡ï¸ æ¸¬è©¦ Temperature = {t} ...")
    try:
        resp = client.chat.completions.create(
            model=MODEL_ID,
            messages=[{"role": "user", "content": prompt}],
            temperature=t,
            max_tokens=200,   # 100å­—ä¸­æ–‡å¤§æ¦‚éœ€è¦ 150~250 tokensï¼Œä¿éšªä¸€é»
        )
        print("ğŸ¤– å›è¦†ï¼š", resp.choices[0].message.content)
    except Exception as e:
        print(f"âŒ ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
